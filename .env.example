# Context Server Environment Configuration
# Copy this file to .env and fill in your values

# OpenAI API Key for embeddings (required for document search functionality)
# Default model: text-embedding-3-large (3072 dimensions)
OPENAI_API_KEY=your_openai_api_key_here

# Voyage AI API Key for code embeddings (required for code search functionality)
# Default model: voyage-code-3 (2048 dimensions)
VOYAGE_API_KEY=your_voyage_api_key_here

# Database Configuration (these match docker-compose.yml defaults)
# Must have pgvector extension with halfvec support
DATABASE_URL=postgresql://context_user:context_password@localhost:5432/context_server

# Logging Configuration
LOG_LEVEL=INFO

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Document Processing Configuration
MAX_CONCURRENT_EXTRACTIONS=3
EMBEDDING_BATCH_SIZE=10

# Chunking Configuration
TEXT_CHUNK_SIZE=1000
TEXT_CHUNK_OVERLAP=200
CODE_CHUNK_SIZE=700
CODE_CHUNK_OVERLAP=150

# Embedding Models (optional overrides)
# OPENAI_EMBEDDING_MODEL=text-embedding-3-large
# VOYAGE_EMBEDDING_MODEL=voyage-code-3

# Optional: Future configurations
# REDIS_URL=redis://localhost:6379
